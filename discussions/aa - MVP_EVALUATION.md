# MVP Evaluation: What Was Built vs. What's Missing

## ‚úÖ What Was Successfully Built

### Foundation Layer (Complete)
- **config.py**: Solid configuration management with environment variables, dataclass-based config, derived path properties, and validation. Covers all required endpoints (Anthropic API, GROBID) and paths.
- **models.py**: Well-structured Pydantic data models with excellent pedagogical comments. Includes all planned metadata fields plus extensibility for later features (flashcards, connections). Covers:
  - `Citation`: Bibliography entries with raw_text and parsed fields
  - `PaperMetadata`: Core paper fields (authors, year, title, venue, DOI, arXiv_id, abstract, citations)
  - `ArticleMetadata`: Web content metadata (URL instead of DOI)
  - `Synthesis`: AI output structure (summary, why_you_cared, key_concepts, memorable_quote, detailed_summary)
  - `ProcessingState`: Deduplication tracking by DOI/arXiv/URL
- **state.py**: StateManager implementation for processing_state.json with singleton pattern, lazy loading, set-based deduplication (fast O(1) lookups), and convenience methods. Good pedagogical comments throughout.
- **docker-compose.yml**: GROBID 0.8.0 container with reasonable memory limits (4GB max, 2GB reserved) and tunable pool size. Ready for local development.
- **env.example**: Clear template with all required variables and comments.

### What This Supports
‚úÖ Configuration loading and validation  
‚úÖ Data model validation (Pydantic)  
‚úÖ Deduplication tracking (three separate sources: DOI, arXiv ID, URL)  
‚úÖ GROBID integration (Docker setup ready)  
‚úÖ State persistence (JSON-based, human-readable)  
‚úÖ Multi-source processing pipeline (arxiv, doi, web)  

---

## ‚ùå What's Missing for MVP Completion

### Critical Path (Must Have Before v0.1.0)

#### 1. **Arrowhead Pipeline Layer** (BLOCKING)
**Status**: NOT BUILT  
**Needed for**: Taking papers from source ‚Üí processed notes in Obsidian vault

What's missing:
- **arxiv_fetcher.py**: Download papers from arXiv by ID, extract metadata via arXiv API
- **doi_fetcher.py**: Resolve DOI ‚Üí PDF URL, fetch PDF, extract metadata via CrossRef/Unpaywall APIs
- **grobid_processor.py**: Send PDFs to GROBID, parse XML response, extract metadata + citations
- **synthesis_generator.py**: Call Claude Haiku with full PDF text, generate (summary, why_you_cared, key_concepts, memorable_quote)
- **markdown_writer.py**: Convert PaperMetadata + Synthesis ‚Üí markdown frontmatter + formatted content for Obsidian

**Impact**: Without this, you can't process papers end-to-end. Everything else is just data structures.

#### 2. **Web Content Handler** (BLOCKING for MVP as decided)
**Status**: NOT BUILT  
**Decided scope**: "Include web content in MVP: arXiv + DOI + web articles + clean PDFs"

What's missing:
- **web_fetcher.py**: Download web content, convert HTML ‚Üí markdown (via markdownify or pypandoc)
- **web_synthesis.py**: Send markdown content to Claude, generate synthesis
- **url_deduplication.py**: Track processed URLs, handle redirects/canonicalization

**Impact**: MVP scope explicitly includes web content, so this is in-scope for v0.1.0, not v0.2.

#### 3. **Main Orchestration Script** (BLOCKING)
**Status**: NOT BUILT  
**What it should do**:
```python
# Pseudocode of orchestration flow
paper = fetch_from_arxiv("2312.12345")  # or fetch_from_doi() or fetch_web()
if state.is_processed(paper.arxiv_id):
    print("Already processed")
    return

metadata = extract_metadata(paper.pdf)  # Via GROBID
synthesis = generate_synthesis(metadata, paper_text)
markdown = render_as_markdown(metadata, synthesis)
write_to_vault(markdown, metadata.arxiv_id)
state.mark_processed(metadata.arxiv_id, "arxiv")
```

Without this, the data models and state manager are orphaned‚Äîthere's no main entry point.

#### 4. **Obsidian Output Format Specification** (MISSING DESIGN)
**Status**: Decided but not implemented  
**What's missing**:
- Example frontmatter format (YAML or JSON?)
- File naming convention (what keys go in filename?)
- Directory structure (Papers/arxiv/2312/, Papers/doi/, Articles/?)
- How to encode links for Obsidian graph (citations as `[[Author, Year]]`?)
- How to structure detailed_summary section (markdown format?)

**Decided direction**: 
- Two-tier synthesis (quick preview + detailed section-by-section)
- Link all citations in paper notes
- Use full author list for disambiguation

But no actual template showing what the output looks like.

---

## ‚ö†Ô∏è Architectural Decisions Made but Partially Implemented

### 1. **Two-Tier Synthesis** (Designed, not implemented)
- ‚úÖ Model supports it: `Synthesis.summary` (quick) + `Synthesis.detailed_summary` (detailed)
- ‚ùå No prompt/code for on-demand generation of detailed_summary
- ‚ùå No UI/trigger for "show detailed summary"

**What's needed**: 
- Prompts for quick vs. detailed synthesis in separate functions
- Logic to detect if detailed_summary exists before re-generating

### 2. **Citation Linking** (Decided, not implemented)
- ‚úÖ Model stores citations: `PaperMetadata.citations: list[Citation]`
- ‚ùå No code to convert citations ‚Üí Obsidian wikilinks
- ‚ùå No deduplication of citations across papers (who did they cite most?)
- ‚ùå No author disambiguation logic (Smith, Jones & Chen 2023 vs Smith, Lee & Park 2023)

**What's needed**:
- Citation formatter that creates `[[Author1, Author2 & Author3, Year]]` links
- Citation index or tracking for future author page generation

### 3. **Metadata Field Coverage** (Decided, implemented in models)
- ‚úÖ Decided fields all in models: authors, year, title, venue, volume/pages, DOI, abstract
- ‚úÖ Page count support ready (models.py has it)
- ‚ö†Ô∏è What about preprint metadata? (arXiv version numbers, update dates?)
- ‚ö†Ô∏è What about annotation metadata? (highlights, notes from tablet reader)

**What's needed**: 
- Annotation extraction pipeline (deferred to v0.1.5 anyway)
- Version tracking for preprints

---

## üìã Decision Points Needing Clarification

### 1. **GROBID vs. OCRmyPDF Timeline**
- ‚úÖ Decided: Use GROBID for all papers + OCRmyPDF for scanned PDFs
- ‚ùå Not decided: When in the pipeline?
  - Before GROBID? (OCRmyPDF ‚Üí GROBID)
  - Parallel? (GROBID on original, OCRmyPDF on failed scans)
  - After? (Fallback if GROBID fails)

**Suggestion**: Implement as fallback first‚Äîtry GROBID, if it fails on scanned PDFs, then OCRmyPDF.

### 2. **Arrowhead Paper Sources**
- You have ~24 arXiv papers ready
- Decided to start with arXiv in v0.1.0
- **Question**: Should arxiv_fetcher.py assume papers are local files or fetch from arXiv API?

**Suggestion**: Both:
1. If arXiv ID found locally (in PDFs/arxiv/ or similar), use that
2. Otherwise, fetch from arXiv API
This maximizes flexibility while supporting your existing dataset.

### 3. **State Tracking Granularity**
- ‚úÖ Current design: Track by identifier (DOI/arXiv/URL)
- ‚ö†Ô∏è What about duplicate detection across sources?
  - Paper exists in arXiv AND via DOI submission
  - Current state.is_processed() would miss this!

**Suggestion**: Optional "version_family" field in ProcessingState to track versions as updates.

---

## üöÄ What to Build Next (Priority Order)

### Phase 1: MVP Core (v0.1.0) ‚Äî Minimum Viable Experiment
1. **grobid_processor.py** - Parse GROBID XML response ‚Üí PaperMetadata
2. **arxiv_fetcher.py** - Fetch papers by ID, extract metadata from arXiv API
3. **synthesis_generator.py** - Claude integration for quick synthesis
4. **markdown_writer.py** - Format output for Obsidian
5. **main.py** - Orchestration script that ties everything together

**Estimated output**: Process your 24 arXiv papers into Obsidian vault with quick synthesis + citations. Run once as experiment, measure token cost + quality.

### Phase 2: MVP Expansion (v0.1.5)
- Web content handler (already decided in scope)
- DOI fetcher (already decided in scope)
- Detailed synthesis on-demand
- Better error handling + logging

### Phase 3: Future
- Annotation extraction
- Author pages
- Connection/graph visualization helpers
- Scanned PDF support (OCRmyPDF integration)

---

## üí° Code Quality Assessment

### Strengths
‚úÖ **Pedagogical**: Every class has "Python concepts" comments explaining what you'll learn  
‚úÖ **Well-modeled**: Pydantic validation ensures data integrity  
‚úÖ **Extensible**: Models have Optional fields for Phase 2 features  
‚úÖ **Testable**: StateManager is a clean class, easy to unit test  
‚úÖ **Production-ready skeleton**: docker-compose + env.example show operational thinking  

### Gaps
‚ùå **No error handling**: What happens if GROBID is down? Network fails? How do we retry?  
‚ùå **No logging**: Hard to debug what's happening in production  
‚ùå **No type hints for complex returns**: Functions will take Dict or JSON responses‚Äîneed type stubs  
‚ùå **No tests**: No test fixtures, no test data, no example processing flows  

---

## üéØ Next Steps Recommendation

**Immediate** (this chat):
1. Identify which missing pieces are blockers for your v0.1.0 experiment
2. Decide on Obsidian output format (show example)
3. Choose: Fetch arXiv papers from API or expect them local?

**Short-term** (next chat):
1. Build grobid_processor.py + arxiv_fetcher.py
2. Create main.py that processes one paper end-to-end
3. Test on 2-3 of your papers, measure costs

**Medium-term**:
1. Batch processing + progress tracking
2. Error handling + retry logic
3. DOI + web content handlers

This pyramid approach gets you an experiment running quickly (core MVP in maybe 500 lines of new code) while building toward full v0.1.0 scope.

---

## Summary Table

| Component | Status | Completeness | Blocker? |
|-----------|--------|--------------|----------|
| Configuration | ‚úÖ Built | 100% | No |
| Data Models | ‚úÖ Built | 95% (annotation fields TODO) | No |
| State Management | ‚úÖ Built | 90% (cross-source dedup TODO) | No |
| GROBID Integration | ‚úÖ Setup | 0% (docker works, no code) | **YES** |
| arXiv Fetcher | ‚ùå Missing | 0% | **YES** |
| DOI Fetcher | ‚ùå Missing | 0% | YES (in scope) |
| Web Fetcher | ‚ùå Missing | 0% | YES (in scope) |
| Synthesis Generator | ‚ùå Missing | 0% | **YES** |
| Markdown Writer | ‚ùå Missing | 0% | **YES** |
| Orchestration Script | ‚ùå Missing | 0% | **YES** |
| Obsidian Format Spec | ‚ùå Missing | 0% | **YES** |
| Error Handling | ‚ùå Missing | 0% | No (Phase 2) |
| Logging | ‚ùå Missing | 0% | No (Phase 2) |
| Tests | ‚ùå Missing | 0% | No (Phase 2) |

